{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_style(\"white\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy.stats as st\n",
    "#import pingouin as pg\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, auc, roc_auc_score, roc_curve, plot_confusion_matrix, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "#from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from statsmodels.api import OLS, add_constant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# information on the variables\n",
    "names=f\"\"\"ID\tID\n",
    "Age\tage\n",
    "Gender\tgender\n",
    "Education\tlevel of education\n",
    "Country\tcountry of current residence\n",
    "Ethnicity\tethnicity\n",
    "Nscore\tNEO-FFI-R Neuroticism\n",
    "Escore\tNEO-FFI-R Extraversion\n",
    "Oscore\tNEO-FFI-R Openness\n",
    "Ascore\tNEO-FFI-R Agreeableness\n",
    "Cscore\tNEO-FFI-R Conscientiousness\n",
    "Impulsive\tBIS-11 Impulsiveness\n",
    "SS\tImpSS sensation\n",
    "Alcohol\talcohol consumption (output attribute)\n",
    "Amphet\tamphetamines consumption (output attribute)\n",
    "Amyl\tamyl nitrite consumption (output attribute)\n",
    "Benzos\tbenzodiazepine consumption (output attribute)\n",
    "Caff\tcaffeine consumption (output attribute)\n",
    "Cannabis\tcannabis consumption (output attribute)\n",
    "Choc\tchocolate consumption (output attribute)\n",
    "Coke\tcocaine consumption (output attribute)\n",
    "Crack\tcrack consumption (output attribute)\n",
    "Ecstasy\tecstasy consumption (output attribute)\n",
    "Heroin\theroin consumption (output attribute)\n",
    "Ketamine\tketamine consumption (output attribute)\n",
    "Legalh\tlegal highs consumption (output attribute)\n",
    "LSD\tLSD consumption (output attribute)\n",
    "Meth\tmethadone consumption (output attribute)\n",
    "Mushrooms\tmagic mushrooms consumption (output attribute)\n",
    "Nicotine\tnicotine consumption (output attribute)\n",
    "Semer\tfictitious drug Semeron consumption (output attribute) Should be removed from our dataset, because of overclaiming observers!\n",
    "VSA\tvolatile substance abuse consumption (output attribute)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url to the dataset\n",
    "url=f\"https://archive.ics.uci.edu/ml/machine-learning-databases/00373/drug_consumption.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset with the column titles\n",
    "def download(url, titles):\n",
    "    df=pd.read_csv(url, header=None)\n",
    "    titles = [row.split(\"\\t\") for row in titles.split(f\"\\n\")]\n",
    "    df.columns=pd.DataFrame(titles)[0]\n",
    "    display(df.info())\n",
    "    print(f\"\"\"Missing Values: \"\"\")\n",
    "    display(df.isna().sum())\n",
    "    print(f\"\"\"Sample of the dataset: \"\"\")\n",
    "    display(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=download(url, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# personality test scores columns\n",
    "scores= [\"Nscore\", \"Escore\", \"Oscore\", \"Ascore\", \"Cscore\", \"Impulsive\", \"SS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups labels for categorical variables\n",
    "age_lb=[\"18-24\", \"25-34\", \"35-44\", \"45-54\", \"55-64\", \"65+\"]\n",
    "gender_lb=[\"Male\", \"Female\"]\n",
    "education_lb=[\"Left before 16\", \"Left at 16\", \"Left at 17\", \"Left at 18\",\"Left at Uni\", \"Certificate/Diploma\", \"University\", \"Masters\", \"PhD\"]\n",
    "country_lb=[\"USA\", \"New Zealand\", \"Other\", \"Australia\",  \"Republic of Ireland\", \"Canada\", \"UK\"]\n",
    "ethnicity_lb=[\"Black\", \"Asian\", \"White\", \"Mixed-White/Black\", \"Other\", \"Mixed-White/Asian\", \"Mixed-Black/Asian\"]\n",
    "user_lb=[\"Non-user\", \"Drug user\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing overclaimers from our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We found the persons or observations who exagertae about drugs they use so we deleted those observation and at the end we removed the Semer column!\n",
    "def semer(df):\n",
    "    display(df.Semer.value_counts())\n",
    "    df.drop(df[df.Semer!=\"CL0\"].index, axis=0, inplace=True)\n",
    "    return df.drop(columns=\"Semer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=semer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transforming the non-numerical columns\n",
    "def non_num_transform(df):\n",
    "    output= list(set(df.columns).difference(set(df._get_numeric_data().columns)))\n",
    "    for o in output:\n",
    "        le = LabelEncoder()\n",
    "        df[o] = le.fit_transform(df[o])\n",
    "    return output\n",
    "\n",
    "output_attributes=non_num_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the Country variable type to categorical one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert intger counrtry into string\n",
    "country = ['USA' if c < -0.5 else \n",
    "           'New Zealand' if c > -0.5 and c < -0.4 else \n",
    "           'Other' if c > -0.4 and c < -0.2 else \n",
    "           'Australia' if c > -0.2 and c < 0 else \n",
    "           'Ireland' if c > 0 and c < 0.23 else \n",
    "           'Canada' if c > 0.23 and c < 0.9 else \n",
    "           'UK' \n",
    "           for c in df['Country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'] = country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the Gender variable type to categorical one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert intger gender to string \n",
    "gender = ['Male' if c == -0.48246 else \n",
    "           'Female'\n",
    "            for c in df['Gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'] = gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender_count = df['Gender'].value_counts()\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(Gender_count.index, Gender_count.values*100/len(df.index), alpha=0.9)\n",
    "plt.title('Frequency Distribution of Gender', fontsize=14)\n",
    "plt.ylabel('Fraction of Participants (%)', fontsize=12)\n",
    "plt.xlabel('Gender', fontsize=12)\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the Age variable type to categorical one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert intger age to string \n",
    "age = ['18-24' if c == -0.95197 else \n",
    "           '25-34' if c == -0.07854 else \n",
    "           '35-44' if c == 0.49788 else \n",
    "           '45-54' if c == 1.09449 else \n",
    "           '55-64' if c == 1.82213 else \n",
    "           '65+'\n",
    "            for c in df['Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Age_count = df['Age'].value_counts()\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(Age_count.index, Age_count.values*100/len(df.index), alpha=0.9)\n",
    "plt.title('Frequency Distribution of Age', fontsize=14)\n",
    "plt.ylabel('Fraction of Participants (%)', fontsize=12)\n",
    "plt.xlabel('Age', fontsize=12)\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the Ethnicity variable type to categorical one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity = [\"Asian\" if c == -0.50212 else \n",
    "           \"Black\" if c == -1.10702 else\n",
    "           \"Mixed-Black/Asian\" if c == 1.90725 else\n",
    "           \"Mixed-White/Asian\" if c == 0.12600 else\n",
    "           \"Mixed-White/Black\" if c == -0.22166 else\n",
    "           \"White\" if c == -0.31685 else\n",
    "           \"Others\"\n",
    "            for c in df['Ethnicity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ethnicity'] = ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ethnicity_count = df['Ethnicity'].value_counts()\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(Ethnicity_count.index, Ethnicity_count.values*100/len(df.index), alpha=0.9)\n",
    "plt.title('Frequency Distribution of Ethnicity', fontsize=14)\n",
    "plt.ylabel('Fraction of Participants (%)', fontsize=12)\n",
    "plt.xlabel('Ethnicity', fontsize=12)\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Education_count = df['Education'].value_counts()\n",
    "sns.set(style=\"darkgrid\")\n",
    "c = 'Education'\n",
    "label=eval(c.lower()+\"_lb\")\n",
    "g = sns.barplot(Education_count.index, Education_count.values*100/len(df.index), alpha=0.9)\n",
    "g.set_xticklabels(label)\n",
    "plt.title('Frequency Distribution of Education', fontsize=14)\n",
    "plt.ylabel('Fraction of Participants (%)', fontsize=12)\n",
    "plt.xlabel('Education', fontsize=12)\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Country_count = df['Country'].value_counts()\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(Country_count.index, Country_count.values*100/len(df.index), alpha=0.9)\n",
    "plt.title('Frequency Distribution of Country', fontsize=14)\n",
    "plt.ylabel('Fraction of Participants (%)', fontsize=12)\n",
    "plt.xlabel('Country', fontsize=12)\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing ID as non-important Feature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the ID column from dataset\n",
    "df.drop(columns=\"ID\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Ethnicty Feature because of being high biased data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.Ethnicity!='White'].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the Ethnicty column from dataset\n",
    "df.drop(columns=\"Ethnicity\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the over claimers and remove these observations from our statset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Higher Nscore more probabilty of using hard drug.\n",
    "* Higher Oscore more probabilty of using hard drug.\n",
    "* lower Ascore more probabilty of using hard drug.\n",
    "* lower Cscore more probabilty of using hard drug.\n",
    "* Higher Impulsive more probabilty of using hard drug.\n",
    "* Higher SS more probabilty of using hard drug.\n",
    "* Men do more drugs than women.\n",
    "* Young people use more drugs than older people.\n",
    "* Low educated people use more drugs than high educated people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Hard Drugs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define what are hard drugs\n",
    "hard_drugs=[\"Amphet\", \"Benzos\", \"Coke\", \"Crack\", \"Ecstasy\", \"Heroin\", \"Legalh\", \"Meth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode a new column to identify whether an individual is a hard drug user or not (with frequency>1)\n",
    "def hard_drug_user(df, hard_drugs):\n",
    "    df[\"hard\"]=df[df[hard_drugs]>2].any(axis=1)\n",
    "    print(f\"The distribution of hard drug user:\")\n",
    "    display(df.hard.value_counts(normalize=True).round(2))\n",
    "    print(f\"Descriptive summary of the hard drug user vs non user on personality test scores:\")\n",
    "    display(df.groupby(\"hard\").agg([\"mean\", \"std\", \"median\", \"min\", \"max\"]).round(2).stack()[[\"Nscore\", \"Escore\", \"Oscore\", \"Ascore\", \"Cscore\", \"Impulsive\", \"SS\"]])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=hard_drug_user(df, hard_drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_count = df['hard'].value_counts()\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(hard_count.index, hard_count.values*100/len(df.index), alpha=0.9)\n",
    "plt.title('Frequency Distribution of Hard Drug Users', fontsize=14)\n",
    "plt.ylabel('Fraction of Participants (%)', fontsize=12)\n",
    "plt.xlabel('Being Hard Drug User', fontsize=12)\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value\tDescription\n",
    "0 - Never Used\n",
    "\n",
    "1 - Used over a Decade Ago\n",
    "\n",
    "2 - Used in Last Decade\n",
    "\n",
    "3 - Used in Last Year\n",
    "\n",
    "4 - Used in Last Month\n",
    "\n",
    "5 - Used in Last Week\n",
    "\n",
    "6 - Used in Last Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_demo(df, cat):\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    graph_name=\"graph/hard drug user by {}.png\"\n",
    "    sns.set(style=\"white\", font_scale = 1.5)\n",
    "    for c in cat:\n",
    "        f, ax = plt.subplots(figsize=(15, 7))\n",
    "        label=eval(c.lower()+\"_lb\")\n",
    "        p=round(pd.pivot_table(df[df.hard==True], values=\"hard\", columns=\"Gender\", index=c, aggfunc=\"count\")/pd.pivot_table(df, values=\"hard\", columns=\"Gender\", index=c, aggfunc=\"count\")*100, 2).reset_index().melt(id_vars=[c])\n",
    "        g=sns.barplot(x=c, y=\"value\", data=p, hue='Gender', palette=[\"b\",\"r\"])\n",
    "        g.set_xticklabels(label)\n",
    "        g.set_ylabel(\"Hard Drug User Percentage\")\n",
    "        g.set_xlabel(f\"{c} Group\")\n",
    "        g.set_title(f\"Distribution of Hard Drug User by {c} and Gender\")\n",
    "        for t, l in zip(g.legend().texts, gender_lb): t.set_text(l)\n",
    "        g.set_xticklabels(g.get_xticklabels(), rotation=15)\n",
    "        #plt.savefig(graph_name.format(c) , transparent=True)\n",
    "        plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define categories\n",
    "cat=[\"Age\", \"Education\", \"Country\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_demo(df,cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=[\"Age\", \"Education\", \"Country\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_demo(df, cat):\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    graph_name=\"graph/hard drug user by {}.png\"\n",
    "    sns.set(style=\"white\", font_scale = 1.5)\n",
    "    for c in cat:\n",
    "        f, ax = plt.subplots(figsize=(15, 7))\n",
    "        label=eval(c.lower()+\"_lb\")\n",
    "        p=round(pd.pivot_table(df, values=\"Nscore\", columns=\"hard\", index=c, aggfunc=\"mean\"), 5).reset_index().melt(id_vars=[c])\n",
    "        g=sns.barplot(x=c, y=\"value\", data=p, hue='hard', palette=[\"b\",\"r\"])\n",
    "        g.set_xticklabels(label)\n",
    "        g.set_ylabel(\"Mean of Nscore\")\n",
    "        g.set_xlabel(f\"{c} Group\")\n",
    "        g.set_title(f\"Variation of mean Nscore by {c} Group and User\")\n",
    "        for t, l in zip(g.legend().texts, user_lb): t.set_text(l)\n",
    "        g.set_xticklabels(g.get_xticklabels(), rotation=15)\n",
    "        #plt.savefig(graph_name.format(c) , transparent=True)\n",
    "        plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_demo(df,cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=[\"Age\", \"Education\", \"Country\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_demo(df, cat):\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    graph_name=\"graph/hard drug user by {}.png\"\n",
    "    sns.set(style=\"white\", font_scale = 1.5)\n",
    "    for c in cat:\n",
    "        f, ax = plt.subplots(figsize=(15, 7))\n",
    "        label=eval(c.lower()+\"_lb\")\n",
    "        p=round(pd.pivot_table(df, values=\"Oscore\", columns=\"hard\", index=c, aggfunc=\"mean\"), 5).reset_index().melt(id_vars=[c])\n",
    "        g=sns.barplot(x=c, y=\"value\", data=p, hue='hard', palette=[\"b\",\"r\"])\n",
    "        g.set_xticklabels(label)\n",
    "        g.set_ylabel(\"Mean of Oscore\")\n",
    "        g.set_xlabel(f\"{c} Group\")\n",
    "        g.set_title(f\"Variation of mean Oscore by {c} Group and User\")\n",
    "        for t, l in zip(g.legend().texts, user_lb): t.set_text(l)\n",
    "        g.set_xticklabels(g.get_xticklabels(), rotation=15)\n",
    "        #plt.savefig(graph_name.format(c) , transparent=True)\n",
    "        plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_demo(df,cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_demo(df, cat):\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    graph_name=\"graph/hard drug user by {}.png\"\n",
    "    sns.set(style=\"white\", font_scale = 1.5)\n",
    "    for c in cat:\n",
    "        f, ax = plt.subplots(figsize=(15, 7))\n",
    "        label=eval(c.lower()+\"_lb\")\n",
    "        p=round(pd.pivot_table(df, values=\"Cscore\", columns=\"hard\", index=c, aggfunc=\"mean\"), 5).reset_index().melt(id_vars=[c])\n",
    "        g=sns.barplot(x=c, y=\"value\", data=p, hue='hard', palette=[\"b\",\"r\"])\n",
    "        g.set_xticklabels(label)\n",
    "        g.set_ylabel(\"Mean of Cscore\")\n",
    "        g.set_xlabel(f\"{c} Group\")\n",
    "        g.set_title(f\"Variation of mean Cscore by {c} Group and User\")\n",
    "        for t, l in zip(g.legend().texts, user_lb): t.set_text(l)\n",
    "        g.set_xticklabels(g.get_xticklabels(), rotation=15)\n",
    "        #plt.savefig(graph_name.format(c) , transparent=True)\n",
    "        plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_demo(df,cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_demo(df, cat):\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    graph_name=\"graph/hard drug user by {}.png\"\n",
    "    sns.set(style=\"white\", font_scale = 1.5)\n",
    "    for c in cat:\n",
    "        f, ax = plt.subplots(figsize=(15, 7))\n",
    "        label=eval(c.lower()+\"_lb\")\n",
    "        p=round(pd.pivot_table(df, values=\"Ascore\", columns=\"hard\", index=c, aggfunc=\"mean\"), 5).reset_index().melt(id_vars=[c])\n",
    "        g=sns.barplot(x=c, y=\"value\", data=p, hue='hard', palette=[\"b\",\"r\"])\n",
    "        g.set_xticklabels(label)\n",
    "        g.set_ylabel(\"Mean of Ascore\")\n",
    "        g.set_xlabel(f\"{c} Group\")\n",
    "        g.set_title(f\"Variation of mean Ascore by {c} Group and User\")\n",
    "        for t, l in zip(g.legend().texts, user_lb): t.set_text(l)\n",
    "        g.set_xticklabels(g.get_xticklabels(), rotation=15)\n",
    "        #plt.savefig(graph_name.format(c) , transparent=True)\n",
    "        plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_demo(df,cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv = ['Age', 'Gender', 'Education', 'Country', 'Nscore', 'Escore', 'Oscore', 'Ascore', 'Cscore', 'Impulsive', 'SS']\n",
    "dv = ['hard']\n",
    "X_train, X_test,y_train,y_test = train_test_split(df[iv], df[dv], test_size= 0.3, random_state=17, stratify=df[dv])\n",
    "y_train=y_train.values.astype(bool).ravel()\n",
    "y_test=y_test.values.astype(bool).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of models toa construct\n",
    "model_list=[\"LogisticRegression\", \"SVC\", \"NuSVC\", \"GaussianNB\", \"DecisionTreeClassifier\", \"RandomForestClassifier\", \"AdaBoostClassifier\", \"KNeighborsClassifier\", \"CatBoostClassifier\"]\n",
    "#\"XGBClassifier\"\n",
    "\n",
    "dct={\"LogisticRegression\": {\"LogisticRegression\": \"LogisticRegression(max_iter=1e8)\", \"LogisticRegressionBalanced\": \"LogisticRegression(max_iter=1e8, class_weight='balanced')\"}, \"SVC\": \"SVC(probability= True)\", \"NuSVC\": \"NuSVC(nu=0.1, probability= True)\",\"RandomForestClassifier\" : {\"RandomForestClassifier\":\"RandomForestClassifier()\", \"RandomForestClassifierBalanced\":\"RandomForestClassifier(class_weight='balanced')\"}, \"KNeighborsClassifier\": {\"KNeighborsClassifier\":\"KNeighborsClassifier(n_neighbors={})\",\"KNeighborsClassifierWeightedDistance\": \"KNeighborsClassifier(weights='distance')\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, m, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred=model.predict(X_test)\n",
    "    if m==\"CatBoostClassifier\":\n",
    "        y_pred=[eval(i) for i in y_pred]\n",
    "    conf=confusion_matrix(y_test, y_pred)\n",
    "    acc=accuracy_score(y_test,y_pred)\n",
    "    rec=recall_score(y_test,y_pred)\n",
    "    pr=precision_score(y_test,y_pred)\n",
    "    f1=f1_score(y_test,y_pred)\n",
    "    #contruct confusion matrix table\n",
    "    \n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # Plot normalized confusion matrix\n",
    "    c=pd.DataFrame(conf, columns=[\"Predicted Non-User\", \"Predicted User\"], index=[\"Actual Non-User\", \"Actual User\"])\n",
    "    c.index.name=m\n",
    "    \n",
    "    if m!=\"CatBoostClassifier\":\n",
    "        cm = plot_confusion_matrix(model, X_test, y_test, display_labels=[\"Non-User\", \"User\"], cmap=plt.cm.Blues, normalize=\"true\")\n",
    "        cm.ax_.set_title(f\"{m} Normalized confusion matrix\")\n",
    "        plt.show()    \n",
    "    else:\n",
    "        display(c)\n",
    "    \n",
    "    model_roc = roc_auc_score(y_test,  y_pred)\n",
    "    fpr,tpr,thresholds=roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "    return [m ,acc.round(2),pr.round(2),rec.round(2),f1.round(2), model_roc.round(2)], [fpr,tpr], c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_elbow(knn, X_train, X_test, y_train, y_test):\n",
    "    error_rate = []\n",
    "    from math import log10, floor\n",
    "    def round_1sf(x):\n",
    "        return round(x, -int(floor(log10(abs(x)))))\n",
    "    upper = int(round_1sf(X_train.shape[0]**0.5))\n",
    "    for i in range(1,upper):\n",
    "        model=eval(knn.format(i))\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred=model.predict(X_test)\n",
    "        error_rate.append(np.mean(y_pred != y_test))\n",
    "    print(\"Elbow curve for k\")\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(range(1,upper),error_rate,color='blue', linestyle='dashed', \n",
    "             marker='o',markerfacecolor='red', markersize=10)\n",
    "    plt.title('Error Rate vs. K Value')\n",
    "    plt.xlabel('K')\n",
    "    plt.ylabel('Error Rate')\n",
    "    plt.show()\n",
    "    print(\"Minimum error:-\",min(error_rate),\"at K =\",error_rate.index(min(error_rate)))\n",
    "    return int(error_rate.index(min(error_rate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_models(models, X_train, X_test, y_train, y_test):\n",
    "    performance=[]\n",
    "    ROC=[]\n",
    "    confusion=[]\n",
    "    for m in models:\n",
    "        if m in dct.keys() and type(dct[m])==str:\n",
    "            model=eval(dct[m])\n",
    "            p, r, c =fit_model(model, m, X_train, X_test, y_train, y_test)\n",
    "            performance.append(p)\n",
    "            ROC.append(r)\n",
    "            confusion.append(c)\n",
    "            \n",
    "        elif m in dct.keys() and type(dct[m])==dict:\n",
    "            for x in list(dct[m].keys()):\n",
    "                if x == \"KNeighborsClassifier\":\n",
    "                    i=knn_elbow(dct[m][x], X_train, X_test, y_train, y_test)\n",
    "                    model=eval(dct[m][x].format(i))\n",
    "                else:\n",
    "                    model=eval(dct[m][x])\n",
    "                p, r, c = fit_model(model, x, X_train, X_test, y_train, y_test)\n",
    "                performance.append(p)\n",
    "                ROC.append(r)\n",
    "                confusion.append(c)\n",
    "\n",
    "        else:\n",
    "            model=eval(m)()\n",
    "            p, r, c= fit_model(model, m, X_train, X_test, y_train, y_test)\n",
    "            performance.append(p)\n",
    "            ROC.append(r)\n",
    "            confusion.append(c)\n",
    "        \n",
    "    perf=pd.DataFrame(performance, columns=[\"Model\", \"Accuracy\", \"Recall\", \"Precision\", \"F1\", \"ROC\"]).set_index(\"Model\")\n",
    "    display(perf)\n",
    "    return perf, ROC, confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance, ROC, confusion = classification_models(model_list, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hypert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of models for GridSearch\n",
    "grid_model_list=[\"LogisticRegression\", \"SVC\", \"RandomForestClassifier\", \"KNeighborsClassifier\"]\n",
    "\n",
    "# parameters for GridSearch\n",
    "from math import log10, floor\n",
    "def round_1sf(x):\n",
    "    return round(x, -int(floor(log10(abs(x)))))\n",
    "upper = int(round_1sf(X_train.shape[0]**0.5))\n",
    "grid_dct={\"LogisticRegression\": dict(solver=['newton-cg', 'lbfgs', 'liblinear'],penalty=['l2'],C=[100, 10, 1.0, 0.1, 0.01, 0.001]), \"SVC\": dict(kernel=['poly', 'rbf', 'sigmoid'],C=[50, 10, 1.0, 0.1, 0.01],gamma=['scale']),\"RandomForestClassifier\" : dict(n_estimators=[10, 100, 1000],max_features=['sqrt', 'log2']), \"KNeighborsClassifier\": dict(n_neighbors=range(1, upper, 2),weights=['uniform', 'distance'],metric=['euclidean', 'manhattan', 'minkowski'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_models(models, parameters, X_train, X_test, y_train, y_test):\n",
    "    performance=[]\n",
    "    ROC=[]\n",
    "    confusion=[]\n",
    "    for m in models:\n",
    "        if m==\"SVC\":\n",
    "            model=SVC(probability= True)\n",
    "        elif m==\"LogisticRegression\":\n",
    "            model=LogisticRegression(max_iter=1e8)\n",
    "        else:\n",
    "            model=eval(m)()\n",
    "        \n",
    "        cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "        gs = GridSearchCV(estimator=model, param_grid=parameters[m], n_jobs=-1, cv=cv, scoring='recall',error_score=0, refit=True)\n",
    "        grid_result = gs.fit(X_train, y_train)\n",
    "        print(\"Best for %s: %f using %s\" % (m, grid_result.best_score_, grid_result.best_params_))\n",
    "        y_pred = gs.predict(X_test)\n",
    "        \n",
    "        conf=confusion_matrix(y_test, y_pred)\n",
    "        acc=accuracy_score(y_test,y_pred)\n",
    "        rec=recall_score(y_test,y_pred)\n",
    "        pr=precision_score(y_test,y_pred)\n",
    "        f1=f1_score(y_test,y_pred)\n",
    "        np.set_printoptions(precision=2)\n",
    "\n",
    "        # Plot normalized confusion matrix\n",
    "        c=pd.DataFrame(conf, columns=[\"Predicted Non-User\", \"Predicted User\"], index=[\"Actual Non-User\", \"Actual User\"])\n",
    "        c.index.name=m\n",
    "        cm = plot_confusion_matrix(gs, X_test, y_test, display_labels=[\"Non-User\", \"User\"], cmap=plt.cm.Blues, normalize=\"true\")\n",
    "        cm.ax_.set_title(f\"{m} Normalized confusion matrix\")\n",
    "        plt.show()\n",
    "        \n",
    "        model_roc = roc_auc_score(y_test,  y_pred)\n",
    "        fpr,tpr,thresholds=roc_curve(y_test, gs.predict_proba(X_test)[:,1])\n",
    "        \n",
    "        plt.style.use('seaborn-whitegrid')\n",
    "        sns.set(style=\"white\", font_scale = 1)\n",
    "        graph_name=\"graph/ROC Grid {}.png\"\n",
    "    \n",
    "        f, ax = plt.subplots(figsize=(10, 10))\n",
    "        plt.clf()\n",
    "        plt.plot(fpr,tpr, label=f'ROC curve={model_roc.round(2)}')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'{m} ROC Grid')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        #plt.savefig(graph_name.format(names[i]) , transparent=True)\n",
    "        plt.show()            \n",
    "               \n",
    "        performance.append([m ,acc.round(2),pr.round(2),rec.round(2),f1.round(2), model_roc.round(2)])\n",
    "        ROC.append([fpr,tpr])\n",
    "        confusion.append(c)\n",
    "        \n",
    "    perf=pd.DataFrame(performance, columns=[\"Model\", \"Accuracy\", \"Recall\", \"Precision\", \"F1\", \"ROC\"]).set_index(\"Model\")\n",
    "    display(perf)\n",
    "    return perf, ROC, confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_performance, grid_ROC, grid_confusion = grid_models(grid_model_list, grid_dct, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier().fit(X_train, y_train)\n",
    "importances = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visuals_script as vs\n",
    "vs.feature_plot(importances, X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
